> ## Computing the speedup and parallel efficiency
>
> Use your *Overall run times* from above to fill in a table like the one below.
>
> | Cores      | Overall run time (s) | Ideal speedup | Actual speedup | Parallel efficiency |
> |------------|----------------------|---------------|----------------|---------------------|
> | 1 (serial) |                      |               |                |                     |
> | 2          |                      |               |                |                     |
> | 4          |                      |               |                |                     |                   
> | 8          |                      |               |                |                     | 
> | 12         |                      |               |                |                     |
> | 24         |                      |               |                |                     |
> | 48         |                      |               |                |                     |             
> | 96        |                      |               |                |                     |
>
> Given your results, try to answer the following questions:
> 
> 1. What is the core count where you get the **most** efficient use of resources, irrespective
>   of run time?
> 2. What is the core count where you get the fastest solution, irrespective of efficiency?
> 3. What do you think a good core count choice would be for this application that balances
>    time to solution and efficiency? Why did you choose this option?
>
> > ## Solution
> >
> > The table below gives example results for {{ site.host_name }} based on the example 
> > runtimes given in the solution above.
> >
> > | Cores      | Overall run time (s) | Ideal speedup | Actual speedup | Parallel efficiency |
> > |------------|----------------------|---------------|----------------|---------------------|
> > |	1 (serial) 	|	5.663701	|	1	|	1	|	100%	|
> > |	2	|	2.899291	|	2	|	1.95347793650241	|	98%	|
> > |	4	|	1.600889	|	4	|	3.53784740853363	|	88%	|
> > |	8	|	0.923882	|	8	|	6.13032941436244	|	77%	|
> > |	12	|	0.676421	|	12	|	8.37304134555255	|	70%	|
> > |	24	|	0.405928	|	24	|	13.9524767939142	|	58%	|
> > |	48	|	0.301597	|	48	|	18.7790362636233	|	39%	|
> > |	96	|	0.236753	|	96	|	23.9224043623523	|	25%	|
> >
> > ### What is the core count where you get the **most** efficient use of resources?
> >
> > Just using a single core is the cheapest (and always will be unless your speedup is better
> > than perfect – “super-linear” speedup). However, it may not be possible to run on small
> > numbers of cores depending on how much memory you need or other technical constraints.
> >
> > **Note:** on most high-end systems, nodes are not shared between users. This means you are
> > charged for all the CPU-cores on a node regardless of whether you actually use them. Typically
> > we would be running on many hundreds of CPU-cores not a few tens, so the real question in
> > practice is: what is the optimal number of nodes to use?
> >
> > ### What is the core count where you get the fastest solution, irrespective of efficiency?
> >
> > 96 cores gives the fastest time to solution.
> >
> > The fastest time to solution does not often make the most efficient use of resources so 
> > to use this option, you may end up wasting your resources. Sometimes, when there is 
> > time pressure to run the calculations, this may be a valid approach to running 
> > applications.
> >
> > ### What do you think a good core count choice would be for this application to use?
> > 
> > 24 cores is probably the most efficient number of cores to use with a 
> > parallel efficiency of 58%.
> >
> > Usually, the best choice is one that delivers good parallel efficiency with an acceptable
> > time to solution. Note that *acceptable time to solution* differs depending on circumstances
> > so this is something that the individual researcher will have to assess. Good parallel
> > efficiency is often considered to be 70% or greater though many researchers will be happy
> > to run in a regime with parallel efficiency greater than 60%. As noted above, running with
> > worse parallel efficiency may also be useful if the time to solution is an overriding factor.
> >
> {: .solution}
> ## Excluding the IO overhead
>
> Now use your *Calculation times* (not the overall run times) to
> compute the speedup and efficiency. How well do you think the
> calculation part has been parallelised?
> > ## Solution
> >
> > The table below gives example results for {{ site.host_name }} based on the example 
> > runtimes given in the solution above.
> >
> > | Cores      | Calculation time (s) | Ideal speedup | Actual speedup | Parallel efficiency |
> > |------------|----------------------|---------------|----------------|---------------------|
> > |	1 (serial)	|	5.409711	|	1	|	1	|	100%
> > |	2	|	2.78805	|	2	|	1.94032065422069	|	97%
> > |	4	|	1.482274	|	4	|	3.64960257010512	|	91%
> > |	8	|	0.793194	|	8	|	6.82016127202173	|	85%
> > |	12	|	0.530674	|	12	|	10.194038147714	|	85%
> > |	24	|	0.267975	|	24	|	20.1873719563392	|	84%
> > |	48	|	0.136709	|	48	|	39.5709938628766	|	82%
> > |	96	|	0.072191	|	96	|	74.9360862157333	|	78%
> >
> {: .solution}
{: .challenge}